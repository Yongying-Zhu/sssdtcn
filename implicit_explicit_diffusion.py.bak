"""
隐式显式扩散模型 - 核心架构

架构流程:
    Input (x_t, mask, observed) 
      ↓
    ├─ 隐式模块 (扩张卷积) → implicit_features
    ├─ 显式模块 (S4) → explicit_features
      ↓
    特征融合 (concat + linear)
      ↓
    残差层 + 扩散步嵌入
      ↓
    预测噪声 ε_θ
    
超参数调优指南:
    1. 特征提取模块:
        - S4: 调整d_state控制状态空间大小
        - TCN: 调整num_layers、dilation_rates控制感受野
    
    2. 融合策略:
        - 简单拼接: concat([implicit, explicit])
        - 注意力融合: attention(implicit, explicit)
        - 门控融合: gate * implicit + (1-gate) * explicit
    
    3. 扩散参数:
        - num_diffusion_steps: 50(快) vs 1000(慢但好)
        - beta_schedule: linear vs cosine
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from .s4_layer import S4Layer
from .dilated_causal_conv import ImplicitExtractionModule

class DiffusionStepEmbedding(nn.Module):
    """
    扩散步嵌入 - 将时间步t编码为向量
    
    使用Transformer风格的位置编码:
        PE(t, 2i) = sin(t / 10000^(2i/d))
        PE(t, 2i+1) = cos(t / 10000^(2i/d))
    """
    
    def __init__(self, dim=128):
        super().__init__()
        self.dim = dim
        
    def forward(self, t):
        """
        输入: t [batch] - 时间步索引
        输出: [batch, dim] - 时间步嵌入向量
        """
        device = t.device
        half_dim = self.dim // 2
        
        # 计算频率
        freqs = torch.exp(
            -math.log(10000) * torch.arange(0, half_dim, device=device) / half_dim
        )
        
        # 计算角度
        args = t.float().unsqueeze(1) * freqs.unsqueeze(0)
        
        # Sin-Cos编码
        embedding = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)
        
        return embedding


class ImplicitExplicitDiffusionModel(nn.Module):
    """
    隐式显式扩散模型 - 主模型
    
    设计理念:
        - 隐式模块: 捕捉局部多尺度模式 (扩张卷积)
        - 显式模块: 捕捉全局长期依赖 (S4)
        - 双通道特征共同指导扩散去噪过程
    """
    
    def __init__(
        self, 
        input_dim,
        hidden_dim=64,
        s4_d_state=64,
        tcn_num_layers=4,
        num_residual_layers=4,
        embedding_dim=128,
        dropout=0.1
    ):
        """
        参数:
            input_dim: 输入特征维度 (传感器数量)
            hidden_dim: 隐藏层维度
            s4_d_state: S4状态空间维度 (调大提升长期依赖建模)
            tcn_num_layers: TCN层数 (调大提升多尺度建模)
            num_residual_layers: 残差层数量
            embedding_dim: 时间步嵌入维度
            dropout: Dropout率
        """
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        
        # ========== 时间步嵌入 ==========
        self.time_embedding = DiffusionStepEmbedding(embedding_dim)
        self.time_projection = nn.Sequential(
            nn.Linear(embedding_dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
        # ========== 隐式特征提取 (扩张因果卷积) ==========
        self.implicit_module = ImplicitExtractionModule(
            input_dim=input_dim,
            hidden_dim=hidden_dim,
            num_layers=tcn_num_layers,
            dropout=dropout
        )
        
        # ========== 显式特征提取 (S4) ==========
        self.explicit_module = nn.ModuleList([
            S4Layer(input_dim, d_state=s4_d_state, dropout=dropout)
            for _ in range(2)  # 2层S4
        ])
        
        # ========== 特征融合层 ==========
        # 融合策略: 拼接隐式和显式特征
        self.fusion_layer = nn.Sequential(
            nn.Linear(input_dim * 2 + hidden_dim, hidden_dim * 2),  # *2是因为拼接了implicit和explicit
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim * 2, hidden_dim)
        )
        
        # ========== 残差层 ==========
        self.residual_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(hidden_dim, hidden_dim * 2),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(hidden_dim * 2, hidden_dim),
                nn.Dropout(dropout)
            ) for _ in range(num_residual_layers)
        ])
        
        # ========== 输出投影 ==========
        self.output_projection = nn.Sequential(
            nn.Linear(hidden_dim, input_dim * 2),
            nn.GELU(),
            nn.Linear(input_dim * 2, input_dim)
        )
        
        # 初始化输出层权重为接近0 (稳定训练初期)
        nn.init.zeros_(self.output_projection[-1].weight)
        nn.init.zeros_(self.output_projection[-1].bias)
        
    def forward(self, x_t, t, mask, observed_data):
        """
        前向传播
        
        输入:
            x_t: [batch, length, input_dim] - 当前时间步的带噪数据
            t: [batch] - 扩散时间步
            mask: [batch, length, input_dim] - 缺失mask (1=缺失, 0=观测)
            observed_data: [batch, length, input_dim] - 观测数据
        
        输出:
            predicted_noise: [batch, length, input_dim] - 预测的噪声
        
        处理流程:
            1. 时间步嵌入
            2. 条件输入: 保留观测值,只对缺失值加噪
            3. 隐式特征提取 (TCN)
            4. 显式特征提取 (S4)
            5. 特征融合 + 时间嵌入
            6. 残差层处理
            7. 输出噪声预测
        """
        batch, length, channels = x_t.shape
        
        # ========== 1. 时间步嵌入 ==========
        t_emb = self.time_embedding(t)  # [batch, embedding_dim]
        t_emb = self.time_projection(t_emb)  # [batch, hidden_dim]
        t_emb = t_emb.unsqueeze(1).expand(-1, length, -1)  # [batch, length, hidden_dim]
        
        # ========== 2. 条件输入 ==========
        # 关键: 只对缺失部分应用扩散,观测部分保持不变
        conditional_input = x_t * mask + observed_data * (1 - mask)
        
        # ========== 3. 隐式特征提取 (多尺度扩张卷积) ==========
        implicit_features = self.implicit_module(conditional_input)  # [batch, length, input_dim]
        
        # ========== 4. 显式特征提取 (S4长期依赖) ==========
        explicit_features = conditional_input
        for s4_layer in self.explicit_module:
            explicit_features = s4_layer(explicit_features)  # [batch, length, input_dim]
        
        # ========== 5. 特征融合 ==========
        # 拼接: [implicit, explicit, time_embedding]
        fused_features = torch.cat([
            implicit_features, 
            explicit_features, 
            t_emb
        ], dim=-1)  # [batch, length, input_dim*2 + hidden_dim]
        
        h = self.fusion_layer(fused_features)  # [batch, length, hidden_dim]
        
        # ========== 6. 残差层 ==========
        for residual_layer in self.residual_layers:
            h = h + residual_layer(h)  # 残差连接
        
        # ========== 7. 输出噪声预测 ==========
        predicted_noise = self.output_projection(h)  # [batch, length, input_dim]
        
        return predicted_noise

